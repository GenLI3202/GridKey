{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Phase 2 MPC Testing Notebook\n",
    "\n",
    "This notebook provides a flexible testing and validation harness for the MPC (Model Predictive Control) simulation framework.\n",
    "\n",
    "**Purpose:** Run MPC rolling horizon simulations with optional meta-optimizer (alpha sweep) and validate results.\n",
    "\n",
    "**Structure:**\n",
    "1. Setup & Imports\n",
    "2. Configuration\n",
    "3. Run MPC Simulation\n",
    "4. Transform & Save Results\n",
    "5. Standard Validation Plots\n",
    "6. MPC-Specific Analysis Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure:\n",
    "\n",
    "1. **Market Data** - ONE of the following options:\n",
    "   - **Option A (Fastest)**: Preprocessed country parquet: `data/parquet/preprocessed/{country}.parquet`\n",
    "   - Example: `de_lu.parquet`, `hu.parquet`, `at.parquet`, `ch.parquet`, `cz.parquet`\n",
    "   - Generated by `py_script/data/generate_preprocessed_country_data.py`\n",
    "   - 10-100x faster than loading Excel\n",
    "\n",
    "   - **Option B (Submission)**: Phase 2 Excel file: `data/TechArena2025_Phase2_data.xlsx`\n",
    "   - Official Huawei Phase 2 data workbook\n",
    "\n",
    "2. **Configuration Files**: Must exist in `data/p2_config/`:\n",
    "   - `mpc_config.json` - MPC horizon/execution settings\n",
    "   - `mpc_test_config.json` - Test scenario parameters\n",
    "   - `solver_config.json` - Solver settings\n",
    "   - `aging_config.json` - Degradation model parameters\n",
    "   - `afrr_ev_weights_config.json` - aFRR activation probabilities\n",
    "\n",
    "3. **Solver**: At least one MILP solver installed (CPLEX, Gurobi, CBC, HiGHS, or GLPK)\n",
    "\n",
    "**Note**: All parameters can be controlled via configuration files for maximum flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## üì¶ 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy_script\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BESSOptimizerModelIII\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# MPC simulation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy_script\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpc_simulator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MPCSimulator\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy_script\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeta_optimizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MetaOptimizer\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy_script\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransform_mpc_results\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     transform_mpc_results_for_viz,\n\u001b[32m     25\u001b[39m     extract_iteration_summary\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m\\\\nas.ads.mwn.de\\ge75pax\\TUM-PC\\TUM_CEM_PhD\\a_tech_arena_hw\\TechArena2025_EMS\\py_script\\mpc\\__init__.py:40\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mRolling Horizon MPC Framework for BESS Optimization\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m====================================================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m    best = meta_opt.find_optimal_alpha()\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpc_simulator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MPCSimulator\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeta_optimizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MetaOptimizer\n\u001b[32m     43\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mMPCSimulator\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMetaOptimizer\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m\\\\nas.ads.mwn.de\\ge75pax\\TUM-PC\\TUM_CEM_PhD\\a_tech_arena_hw\\TechArena2025_EMS\\py_script\\mpc\\mpc_simulator.py:48\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     47\u001b[39m sys.path.append(\u001b[38;5;28mstr\u001b[39m(Path(\u001b[34m__file__\u001b[39m).parent.parent))\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BESSOptimizerModelIII\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_solution\n\u001b[32m     51\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m\\\\nas.ads.mwn.de\\ge75pax\\TUM-PC\\TUM_CEM_PhD\\a_tech_arena_hw\\TechArena2025_EMS\\py_script\\core\\__init__.py:18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mCore BESS Optimization Module\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m==============================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[33;03m- DataProcessingError, DataValidationError: Custom exception classes\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     BESSOptimizerV2,\n\u001b[32m     14\u001b[39m     BESSOptimizerModelII,\n\u001b[32m     15\u001b[39m     BESSOptimizerV3,\n\u001b[32m     16\u001b[39m     BESSOptimizer_Phase2_ModelII,\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     DataProcessingError,\n\u001b[32m     20\u001b[39m     DataLoadingError,\n\u001b[32m     21\u001b[39m     DataValidationError,\n\u001b[32m     22\u001b[39m     VisualizationError,\n\u001b[32m     23\u001b[39m     format_exception_for_logging\n\u001b[32m     24\u001b[39m )\n\u001b[32m     26\u001b[39m __all__ = [\n\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBESSOptimizerV2\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     28\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBESSOptimizerModelII\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mformat_exception_for_logging\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     36\u001b[39m ]\n\u001b[32m     38\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m2.0.0\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Optimization models\n",
    "from py_script.core.optimizer import BESSOptimizerModelIII\n",
    "\n",
    "# MPC simulation\n",
    "from py_script.mpc.mpc_simulator import MPCSimulator\n",
    "from py_script.mpc.meta_optimizer import MetaOptimizer\n",
    "from py_script.mpc.transform_mpc_results import (\n",
    "    transform_mpc_results_for_viz,\n",
    "    extract_iteration_summary\n",
    ")\n",
    "\n",
    "# Data loading\n",
    "from py_script.data.load_process_market_data import load_preprocessed_country_data\n",
    "\n",
    "# Standard visualization utilities\n",
    "from py_script.visualization.optimization_analysis import (\n",
    "    plot_da_market_price_bid,\n",
    "    plot_afrr_energy_market_price_bid,\n",
    "    plot_capacity_markets_price_bid,\n",
    "    plot_soc_and_power_bids\n",
    ")\n",
    "\n",
    "# MPC-specific visualization\n",
    "from py_script.visualization.mpc_analysis import (\n",
    "    plot_iteration_boundaries,\n",
    "    plot_iteration_performance,\n",
    "    plot_state_continuity\n",
    ")\n",
    "\n",
    "# Results export\n",
    "from py_script.validation.results_exporter import save_optimization_results\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Configuration\n",
    "\n",
    "Load all configuration files and define MPC scenario parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Configuration Files\n",
    "# ============================================================================\n",
    "\n",
    "# Define configuration paths\n",
    "config_dir = project_root / \"data\" / \"p2_config\"\n",
    "\n",
    "# Load MPC configuration\n",
    "mpc_config_path = config_dir / \"mpc_config.json\"\n",
    "with open(mpc_config_path, 'r') as f:\n",
    "    mpc_config = json.load(f)\n",
    "    print(f\"‚úÖ Loaded MPC config: {mpc_config_path.name}\")\n",
    "\n",
    "# Load MPC test configuration\n",
    "mpc_test_config_path = config_dir / \"mpc_test_config.json\"\n",
    "with open(mpc_test_config_path, 'r') as f:\n",
    "    mpc_test_config = json.load(f)\n",
    "    print(f\"‚úÖ Loaded MPC test config: {mpc_test_config_path.name}\")\n",
    "\n",
    "# Load solver config\n",
    "solver_config_path = config_dir / \"solver_config.json\"\n",
    "with open(solver_config_path, 'r') as f:\n",
    "    solver_config = json.load(f)\n",
    "    print(f\"‚úÖ Loaded solver config: {solver_config_path.name}\")\n",
    "\n",
    "# Load aging config\n",
    "aging_config_path = config_dir / \"aging_config.json\"\n",
    "with open(aging_config_path, 'r') as f:\n",
    "    aging_config = json.load(f)\n",
    "    print(f\"‚úÖ Loaded aging config: {aging_config_path.name}\")\n",
    "\n",
    "# Load aFRR EV weights config\n",
    "afrr_ev_config_path = config_dir / \"afrr_ev_weights_config.json\"\n",
    "with open(afrr_ev_config_path, 'r') as f:\n",
    "    afrr_ev_config = json.load(f)\n",
    "    print(f\"‚úÖ Loaded aFRR EV config: {afrr_ev_config_path.name}\")\n",
    "\n",
    "print(\"\\nConfiguration files loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Extract Scenario Parameters from Config\n",
    "# ============================================================================\n",
    "\n",
    "# Test scenario (from mpc_test_config.json)\n",
    "TEST_COUNTRY = mpc_test_config['test_scenario']['country']\n",
    "TEST_DURATION_DAYS = mpc_test_config['test_scenario']['duration_days']\n",
    "TEST_C_RATE = mpc_test_config['test_scenario']['c_rate']\n",
    "DATA_SOURCE = mpc_test_config['test_scenario']['data_source']\n",
    "\n",
    "# Alpha settings\n",
    "ALPHA_MODE = mpc_test_config['alpha_settings']['mode']\n",
    "SINGLE_ALPHA = mpc_test_config['alpha_settings']['single_alpha']\n",
    "ALPHA_SWEEP_RANGE = mpc_test_config['alpha_settings']['sweep_range']\n",
    "\n",
    "# Meta-optimizer settings\n",
    "ENABLE_META_OPTIMIZER = mpc_test_config['meta_optimizer']['enabled']\n",
    "META_N_JOBS = mpc_test_config['meta_optimizer']['n_jobs']\n",
    "META_WACC = mpc_test_config['meta_optimizer']['wacc']\n",
    "META_INFLATION = mpc_test_config['meta_optimizer']['inflation_rate']\n",
    "META_LIFETIME = mpc_test_config['meta_optimizer']['project_lifetime_years']\n",
    "\n",
    "# MPC execution settings (from mpc_config.json)\n",
    "HORIZON_HOURS = mpc_config['mpc_parameters']['horizon_hours']\n",
    "EXECUTION_HOURS = mpc_config['mpc_parameters']['execution_hours']\n",
    "INITIAL_SOC_FRACTION = mpc_config['mpc_parameters']['initial_soc_fraction']\n",
    "VALIDATE_CONSTRAINTS = mpc_config['mpc_parameters']['validate_constraints']\n",
    "\n",
    "# Max iterations (from mpc_test_config.json)\n",
    "MAX_ITERATIONS = mpc_test_config['mpc_execution']['max_iterations']\n",
    "\n",
    "# Visualization settings\n",
    "ENABLE_STANDARD_PLOTS = mpc_test_config['visualization']['enable_standard_plots']\n",
    "ENABLE_MPC_PLOTS = mpc_test_config['visualization']['enable_mpc_plots']\n",
    "MPC_PLOT_OPTIONS = mpc_test_config['visualization']['mpc_plot_options']\n",
    "SAVE_FORMAT = mpc_test_config['visualization']['save_format']\n",
    "\n",
    "# Output settings\n",
    "SAVE_RESULTS = mpc_test_config['output']['save_results']\n",
    "BASE_OUTPUT_DIR = mpc_test_config['output']['base_output_dir']\n",
    "AUTO_GENERATE_RUN_NAME = mpc_test_config['output']['auto_generate_run_name']\n",
    "CUSTOM_RUN_NAME = mpc_test_config['output']['custom_run_name']\n",
    "\n",
    "# Display scenario summary\n",
    "print(\"=\" * 80)\n",
    "print(\"üìã MPC TEST SCENARIO CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Country:              {TEST_COUNTRY}\")\n",
    "print(f\"Test Duration:        {TEST_DURATION_DAYS} days\")\n",
    "print(f\"C-Rate:               {TEST_C_RATE}\")\n",
    "print(f\"Data Source:          {DATA_SOURCE}\")\n",
    "print()\n",
    "print(\"MPC Settings:\")\n",
    "print(f\"  Horizon:            {HORIZON_HOURS} hours\")\n",
    "print(f\"  Execution:          {EXECUTION_HOURS} hours\")\n",
    "print(f\"  Initial SOC:        {INITIAL_SOC_FRACTION * 100:.0f}%\")\n",
    "print(f\"  Max Iterations:     {MAX_ITERATIONS if MAX_ITERATIONS else 'Full duration'}\")\n",
    "print()\n",
    "print(\"Alpha Settings:\")\n",
    "if ALPHA_MODE == 'single':\n",
    "    print(f\"  Mode:               Single alpha\")\n",
    "    print(f\"  Alpha:              {SINGLE_ALPHA}\")\n",
    "else:\n",
    "    print(f\"  Mode:               Sweep\")\n",
    "    print(f\"  Range:              {ALPHA_SWEEP_RANGE['min']} - {ALPHA_SWEEP_RANGE['max']} (step {ALPHA_SWEEP_RANGE['step']})\")\n",
    "print()\n",
    "print(\"Meta-Optimizer:\")\n",
    "print(f\"  Enabled:            {ENABLE_META_OPTIMIZER}\")\n",
    "if ENABLE_META_OPTIMIZER:\n",
    "    print(f\"  Parallel Jobs:      {META_N_JOBS}\")\n",
    "    print(f\"  WACC:               {META_WACC * 100:.1f}%\")\n",
    "    print(f\"  Inflation:          {META_INFLATION * 100:.1f}%\")\n",
    "    print(f\"  Project Lifetime:   {META_LIFETIME} years\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Load Market Data\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate number of timesteps\n",
    "duration_timesteps = TEST_DURATION_DAYS * 96  # 96 timesteps per day (15-min intervals)\n",
    "\n",
    "if DATA_SOURCE == 'preprocessed':\n",
    "    # Option 1: Load preprocessed country-specific parquet (FASTEST)\n",
    "    preprocessed_dir = project_root / \"data\" / \"parquet\" / \"preprocessed\"\n",
    "    preprocessed_path = preprocessed_dir / f\"{TEST_COUNTRY.lower()}.parquet\"\n",
    "    \n",
    "    if preprocessed_path.exists():\n",
    "        print(f\"[FAST PATH] Loading preprocessed data: {preprocessed_path.name}\")\n",
    "        country_data = load_preprocessed_country_data(TEST_COUNTRY, data_dir=preprocessed_dir)\n",
    "        print(f\"[OK] Loaded {len(country_data)} time steps for {TEST_COUNTRY} (preprocessed)\")\n",
    "    else:\n",
    "        print(f\"ERROR: Preprocessed file not found: {preprocessed_path}\")\n",
    "        print(\"Falling back to Excel...\")\n",
    "        DATA_SOURCE = 'excel'\n",
    "\n",
    "if DATA_SOURCE == 'excel':\n",
    "    # Option 2: Load from Excel (SUBMISSION PATH)\n",
    "    excel_path = project_root / \"data\" / \"TechArena2025_Phase2_data.xlsx\"\n",
    "    \n",
    "    if excel_path.exists():\n",
    "        print(f\"[SUBMISSION PATH] Loading from Excel: {excel_path.name}\")\n",
    "        print(\"   This matches Huawei submission requirements...\")\n",
    "        \n",
    "        # Create temporary optimizer for data loading\n",
    "        temp_opt = BESSOptimizerModelIII()\n",
    "        \n",
    "        # Load using Phase 2 Excel loader\n",
    "        print(\"   Loading Phase 2 market tables from Excel...\")\n",
    "        full_data = temp_opt.load_and_preprocess_data(str(excel_path))\n",
    "        \n",
    "        # Extract country-specific data\n",
    "        print(f\"   Extracting country data for {TEST_COUNTRY}...\")\n",
    "        country_data = temp_opt.extract_country_data(full_data, TEST_COUNTRY)\n",
    "        print(f\"[OK] Loaded {len(country_data)} time steps for {TEST_COUNTRY} (Excel)\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Excel file not found: {excel_path}\")\n",
    "\n",
    "# Slice to test duration\n",
    "if duration_timesteps > len(country_data):\n",
    "    print(f\"\\nWARNING: Requested {duration_timesteps} timesteps but only {len(country_data)} available\")\n",
    "    print(f\"Using full dataset ({len(country_data) // 96} days)\")\n",
    "    country_data_slice = country_data.copy()\n",
    "else:\n",
    "    country_data_slice = country_data.iloc[:duration_timesteps].copy()\n",
    "    print(f\"\\n[OK] Sliced to {TEST_DURATION_DAYS} days ({len(country_data_slice)} timesteps)\")\n",
    "\n",
    "# Display data summary\n",
    "print(f\"\\nMarket Data Summary:\")\n",
    "print(f\"   DA Price:           {country_data_slice['price_day_ahead'].min():.2f} - {country_data_slice['price_day_ahead'].max():.2f} EUR/MWh\")\n",
    "print(f\"   FCR Price:          {country_data_slice['price_fcr'].min():.2f} - {country_data_slice['price_fcr'].max():.2f} EUR/MW\")\n",
    "print(f\"   aFRR+ Cap Price:    {country_data_slice['price_afrr_pos'].min():.2f} - {country_data_slice['price_afrr_pos'].max():.2f} EUR/MW\")\n",
    "print(f\"   aFRR- Cap Price:    {country_data_slice['price_afrr_neg'].min():.2f} - {country_data_slice['price_afrr_neg'].max():.2f} EUR/MW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## üöÄ 3. Run MPC Simulation\n",
    "\n",
    "Execute MPC rolling horizon simulation with optional meta-optimizer for alpha sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mpc_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Initialize and Run MPC Simulation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üöÄ RUNNING MPC SIMULATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "simulation_start = time.time()\n",
    "\n",
    "if ENABLE_META_OPTIMIZER and ALPHA_MODE == 'sweep':\n",
    "    # Use Meta-Optimizer for alpha sweep\n",
    "    print(f\"\\n[MODE] Meta-Optimizer (Alpha Sweep)\")\n",
    "    print(f\"   Alpha range: {ALPHA_SWEEP_RANGE['min']} - {ALPHA_SWEEP_RANGE['max']} (step {ALPHA_SWEEP_RANGE['step']})\")\n",
    "    print(f\"   Parallel jobs: {META_N_JOBS}\")\n",
    "    print()\n",
    "    \n",
    "    # Generate alpha values\n",
    "    alpha_values = np.arange(\n",
    "        ALPHA_SWEEP_RANGE['min'],\n",
    "        ALPHA_SWEEP_RANGE['max'] + ALPHA_SWEEP_RANGE['step'] / 2,\n",
    "        ALPHA_SWEEP_RANGE['step']\n",
    "    )\n",
    "    \n",
    "    # Initialize Meta-Optimizer\n",
    "    meta_opt = MetaOptimizer(\n",
    "        optimizer_class=BESSOptimizerModelIII,\n",
    "        country_data=country_data_slice,\n",
    "        c_rate=TEST_C_RATE,\n",
    "        horizon_hours=HORIZON_HOURS,\n",
    "        execution_hours=EXECUTION_HOURS,\n",
    "        wacc=META_WACC,\n",
    "        inflation_rate=META_INFLATION,\n",
    "        project_lifetime_years=META_LIFETIME,\n",
    "        n_jobs=META_N_JOBS\n",
    "    )\n",
    "    \n",
    "    # Run meta-optimization\n",
    "    best_alpha, best_roi, all_results = meta_opt.optimize_alpha(\n",
    "        alpha_values,\n",
    "        initial_soc_fraction=INITIAL_SOC_FRACTION,\n",
    "        max_iterations=MAX_ITERATIONS\n",
    "    )\n",
    "    \n",
    "    # Extract best result\n",
    "    mpc_results = all_results[best_alpha]['mpc_results']\n",
    "    used_alpha = best_alpha\n",
    "    \n",
    "    print(f\"\\n‚úÖ Meta-Optimization Complete!\")\n",
    "    print(f\"   Best Alpha: {best_alpha}\")\n",
    "    print(f\"   Best ROI:   {best_roi:.2f}%\")\n",
    "    \n",
    "else:\n",
    "    # Single alpha MPC simulation\n",
    "    used_alpha = SINGLE_ALPHA\n",
    "    print(f\"\\n[MODE] Single Alpha MPC Simulation\")\n",
    "    print(f\"   Alpha: {used_alpha}\")\n",
    "    print(f\"   Horizon: {HORIZON_HOURS}h\")\n",
    "    print(f\"   Execution: {EXECUTION_HOURS}h\")\n",
    "    print()\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = BESSOptimizerModelIII(alpha=used_alpha)\n",
    "    \n",
    "    # Initialize MPC simulator\n",
    "    simulator = MPCSimulator(\n",
    "        optimizer_model=optimizer,\n",
    "        full_data=country_data_slice,\n",
    "        horizon_hours=HORIZON_HOURS,\n",
    "        execution_hours=EXECUTION_HOURS,\n",
    "        c_rate=TEST_C_RATE,\n",
    "        validate_constraints=VALIDATE_CONSTRAINTS\n",
    "    )\n",
    "    \n",
    "    # Run simulation\n",
    "    mpc_results = simulator.run_full_simulation(\n",
    "        initial_soc_fraction=INITIAL_SOC_FRACTION,\n",
    "        max_iterations=MAX_ITERATIONS\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ MPC Simulation Complete!\")\n",
    "\n",
    "simulation_time = time.time() - simulation_start\n",
    "\n",
    "# Display results summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä MPC RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Revenue:          ‚Ç¨{mpc_results['total_revenue']:,.2f}\")\n",
    "print(f\"Total Degradation Cost: ‚Ç¨{mpc_results['total_degradation_cost']:,.2f}\")\n",
    "print(f\"Net Profit:             ‚Ç¨{mpc_results['net_profit']:,.2f}\")\n",
    "print()\n",
    "print(f\"Final SOC:              {mpc_results['final_soc']:.2f} kWh\")\n",
    "print(f\"Number of Iterations:   {len(mpc_results['iteration_results'])}\")\n",
    "print(f\"Simulation Time:        {simulation_time:.2f}s ({simulation_time/60:.2f} min)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## üì¶ 4. Transform & Save Results\n",
    "\n",
    "Transform MPC results to visualization format and save to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Transform MPC Results for Visualization\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîÑ TRANSFORMING RESULTS FOR VISUALIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extract annual bids DataFrame\n",
    "annual_bids_df = mpc_results['annual_bids_df']\n",
    "print(f\"Annual bids DataFrame: {annual_bids_df.shape[0]} timesteps\")\n",
    "\n",
    "# Transform to visualization format\n",
    "viz_df = transform_mpc_results_for_viz(\n",
    "    annual_bids_df,\n",
    "    country_data_slice,\n",
    "    battery_capacity_kwh=4472.0\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Transformed to visualization format\")\n",
    "print(f\"   Columns: {len(viz_df.columns)}\")\n",
    "print(f\"   Rows:    {len(viz_df)}\")\n",
    "\n",
    "# Extract iteration summary\n",
    "iteration_summary = extract_iteration_summary(mpc_results, include_soc_trajectory=True)\n",
    "print(f\"\\n‚úÖ Extracted iteration summary: {len(iteration_summary)} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Prepare Summary Metrics\n",
    "# ============================================================================\n",
    "\n",
    "# Build summary metrics dictionary\n",
    "summary_metrics = {\n",
    "    'model': 'Model_III_MPC',\n",
    "    'country': TEST_COUNTRY,\n",
    "    'test_duration_days': TEST_DURATION_DAYS,\n",
    "    'alpha': used_alpha,\n",
    "    'c_rate': TEST_C_RATE,\n",
    "    \n",
    "    # MPC settings\n",
    "    'mpc_horizon_hours': HORIZON_HOURS,\n",
    "    'mpc_execution_hours': EXECUTION_HOURS,\n",
    "    'mpc_initial_soc_fraction': INITIAL_SOC_FRACTION,\n",
    "    'mpc_iterations': len(mpc_results['iteration_results']),\n",
    "    \n",
    "    # Financial results\n",
    "    'total_profit_eur': mpc_results['net_profit'],\n",
    "    'total_revenue_eur': mpc_results['total_revenue'],\n",
    "    'total_degradation_eur': mpc_results['total_degradation_cost'],\n",
    "    \n",
    "    # Revenue breakdown (if available)\n",
    "    'revenue_da_eur': mpc_results.get('da_revenue', 0),\n",
    "    'revenue_afrr_energy_eur': mpc_results.get('afrr_e_revenue', 0),\n",
    "    'revenue_as_capacity_eur': mpc_results.get('as_revenue', 0),\n",
    "    \n",
    "    # Degradation breakdown (if available)\n",
    "    'degradation_cyclic_eur': mpc_results.get('cyclic_cost', 0),\n",
    "    'degradation_calendar_eur': mpc_results.get('calendar_cost', 0),\n",
    "    \n",
    "    # SOC metrics\n",
    "    'initial_soc_kwh': mpc_results['soc_trajectory'][0] if mpc_results['soc_trajectory'] else INITIAL_SOC_FRACTION * 4472,\n",
    "    'final_soc_kwh': mpc_results['final_soc'],\n",
    "    \n",
    "    # Timing\n",
    "    'simulation_time_sec': simulation_time,\n",
    "    \n",
    "    # Data source\n",
    "    'data_source': DATA_SOURCE\n",
    "}\n",
    "\n",
    "# Add meta-optimizer results if applicable\n",
    "if ENABLE_META_OPTIMIZER and ALPHA_MODE == 'sweep':\n",
    "    summary_metrics['meta_optimizer'] = {\n",
    "        'enabled': True,\n",
    "        'best_alpha': best_alpha,\n",
    "        'best_roi': best_roi,\n",
    "        'alpha_range': {\n",
    "            'min': ALPHA_SWEEP_RANGE['min'],\n",
    "            'max': ALPHA_SWEEP_RANGE['max'],\n",
    "            'step': ALPHA_SWEEP_RANGE['step']\n",
    "        },\n",
    "        'all_alphas': {str(float(a)): float(all_results[a]['roi']) for a in alpha_values}\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Summary metrics prepared\")\n",
    "print(f\"\\nTotal Revenue: ‚Ç¨{summary_metrics['total_revenue_eur']:,.2f}\")\n",
    "print(f\"Total Profit:  ‚Ç¨{summary_metrics['total_profit_eur']:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Save Results to Disk\n",
    "# ============================================================================\n",
    "\n",
    "if SAVE_RESULTS:\n",
    "    # Generate run name\n",
    "    if AUTO_GENERATE_RUN_NAME:\n",
    "        run_name = f\"mpc_{TEST_COUNTRY}_{TEST_DURATION_DAYS}d_alpha{used_alpha}\"\n",
    "        if ENABLE_META_OPTIMIZER:\n",
    "            run_name += \"_meta\"\n",
    "    else:\n",
    "        run_name = CUSTOM_RUN_NAME if CUSTOM_RUN_NAME else \"mpc_test\"\n",
    "    \n",
    "    # Save using results_exporter\n",
    "    output_directory = save_optimization_results(\n",
    "        viz_df,\n",
    "        summary_metrics,\n",
    "        run_name,\n",
    "        base_output_dir=str(project_root / BASE_OUTPUT_DIR)\n",
    "    )\n",
    "    \n",
    "    # Also save iteration summary\n",
    "    iteration_csv_path = output_directory / \"iteration_summary.csv\"\n",
    "    iteration_summary.to_csv(iteration_csv_path, index=False)\n",
    "    print(f\"   üìä iteration_summary.csv\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üíæ RESULTS SAVED SUCCESSFULLY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üìÅ Output directory: {output_directory}\")\n",
    "    print(f\"   üìä solution_timeseries.csv\")\n",
    "    print(f\"   üìä iteration_summary.csv\")\n",
    "    print(f\"   üìã performance_summary.json\")\n",
    "    print(f\"   üìà plots/ (subdirectory created)\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚ö†Ô∏è RESULTS NOT SAVED (SAVE_RESULTS = False)\")\n",
    "    print(\"=\" * 80)\n",
    "    output_directory = Path(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## üìä 5. Standard Validation Plots\n",
    "\n",
    "Generate standard market participation plots (same as single-pass optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard_plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_STANDARD_PLOTS:\n",
    "    # Define plots directory\n",
    "    plots_dir = output_directory / \"plots\" if SAVE_RESULTS else Path(\".\")\n",
    "    title_suffix = f\"MPC {TEST_COUNTRY} - {TEST_DURATION_DAYS}d - {HORIZON_HOURS}h/{EXECUTION_HOURS}h\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä GENERATING STANDARD MARKET PLOTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Plot 1: Day-Ahead Market\n",
    "    print(\"\\n[1/4] Day-Ahead Market...\")\n",
    "    fig_da = plot_da_market_price_bid(viz_df, title_suffix=title_suffix, use_timestamp=True)\n",
    "    if SAVE_RESULTS:\n",
    "        fig_da.write_html(str(plots_dir / f\"da_market_price_bid.{SAVE_FORMAT}\"))\n",
    "    fig_da.show()\n",
    "    print(\"   ‚úÖ Saved: da_market_price_bid.html\")\n",
    "    \n",
    "    # Plot 2: aFRR Energy Market\n",
    "    print(\"\\n[2/4] aFRR Energy Market...\")\n",
    "    fig_afrr_e = plot_afrr_energy_market_price_bid(viz_df, title_suffix=title_suffix, use_timestamp=True)\n",
    "    if SAVE_RESULTS:\n",
    "        fig_afrr_e.write_html(str(plots_dir / f\"afrr_energy_market_price_bid.{SAVE_FORMAT}\"))\n",
    "    fig_afrr_e.show()\n",
    "    print(\"   ‚úÖ Saved: afrr_energy_market_price_bid.html\")\n",
    "    \n",
    "    # Plot 3: Capacity Markets\n",
    "    print(\"\\n[3/4] Capacity Markets...\")\n",
    "    fig_cap = plot_capacity_markets_price_bid(viz_df, title_suffix=title_suffix, use_timestamp=True)\n",
    "    if SAVE_RESULTS:\n",
    "        fig_cap.write_html(str(plots_dir / f\"capacity_markets_price_bid.{SAVE_FORMAT}\"))\n",
    "    fig_cap.show()\n",
    "    print(\"   ‚úÖ Saved: capacity_markets_price_bid.html\")\n",
    "    \n",
    "    # Plot 4: SOC & Power Bids\n",
    "    print(\"\\n[4/4] SOC & Power Bids...\")\n",
    "    fig_soc = plot_soc_and_power_bids(viz_df, title_suffix=title_suffix, use_timestamp=True)\n",
    "    if SAVE_RESULTS:\n",
    "        fig_soc.write_html(str(plots_dir / f\"soc_and_power_bids.{SAVE_FORMAT}\"))\n",
    "    fig_soc.show()\n",
    "    print(\"   ‚úÖ Saved: soc_and_power_bids.html\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ All standard market plots generated!\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Standard plots disabled (ENABLE_STANDARD_PLOTS = False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## üîç 6. MPC-Specific Analysis Plots\n",
    "\n",
    "Generate MPC-specific visualizations for analyzing rolling horizon behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mpc_plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_MPC_PLOTS:\n",
    "    plots_dir = output_directory / \"plots\" if SAVE_RESULTS else Path(\".\")\n",
    "    title_suffix = f\"MPC {TEST_COUNTRY} - {TEST_DURATION_DAYS}d\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üîç GENERATING MPC-SPECIFIC ANALYSIS PLOTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Plot 1: Iteration Boundaries\n",
    "    if MPC_PLOT_OPTIONS['iteration_boundaries']:\n",
    "        print(\"\\n[1/3] Iteration Boundaries...\")\n",
    "        fig_boundaries = plot_iteration_boundaries(\n",
    "            mpc_results,\n",
    "            execution_hours=EXECUTION_HOURS,\n",
    "            title_suffix=title_suffix,\n",
    "            show_horizons=False\n",
    "        )\n",
    "        if SAVE_RESULTS:\n",
    "            fig_boundaries.write_html(str(plots_dir / f\"mpc_iteration_boundaries.{SAVE_FORMAT}\"))\n",
    "        fig_boundaries.show()\n",
    "        print(\"   ‚úÖ Saved: mpc_iteration_boundaries.html\")\n",
    "    \n",
    "    # Plot 2: Iteration Performance\n",
    "    if MPC_PLOT_OPTIONS['iteration_performance']:\n",
    "        print(\"\\n[2/3] Iteration Performance...\")\n",
    "        fig_performance = plot_iteration_performance(\n",
    "            mpc_results,\n",
    "            title_suffix=title_suffix,\n",
    "            show_cumulative=True\n",
    "        )\n",
    "        if SAVE_RESULTS:\n",
    "            fig_performance.write_html(str(plots_dir / f\"mpc_iteration_performance.{SAVE_FORMAT}\"))\n",
    "        fig_performance.show()\n",
    "        print(\"   ‚úÖ Saved: mpc_iteration_performance.html\")\n",
    "    \n",
    "    # Plot 3: State Continuity\n",
    "    if MPC_PLOT_OPTIONS['state_continuity']:\n",
    "        print(\"\\n[3/3] State Continuity Check...\")\n",
    "        fig_continuity = plot_state_continuity(\n",
    "            mpc_results,\n",
    "            title_suffix=title_suffix,\n",
    "            tolerance_pct=0.1\n",
    "        )\n",
    "        if SAVE_RESULTS:\n",
    "            fig_continuity.write_html(str(plots_dir / f\"mpc_state_continuity.{SAVE_FORMAT}\"))\n",
    "        fig_continuity.show()\n",
    "        print(\"   ‚úÖ Saved: mpc_state_continuity.html\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ All MPC analysis plots generated!\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è MPC plots disabled (ENABLE_MPC_PLOTS = False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Notebook Complete!\n",
    "\n",
    "### What was accomplished:\n",
    "1. ‚úÖ Loaded all configuration files (MPC, test, solver, aging, aFRR)\n",
    "2. ‚úÖ Loaded market data (preprocessed or Excel)\n",
    "3. ‚úÖ Ran MPC rolling horizon simulation (with optional meta-optimizer)\n",
    "4. ‚úÖ Transformed results to visualization format\n",
    "5. ‚úÖ Saved results using `results_exporter`\n",
    "6. ‚úÖ Generated standard market participation plots\n",
    "7. ‚úÖ Generated MPC-specific analysis plots\n",
    "\n",
    "### Output location:\n",
    "All results are saved in the timestamped directory under `validation_results/mpc_validation/`\n",
    "\n",
    "### Next steps:\n",
    "- Modify parameters in `data/p2_config/mpc_test_config.json` and re-run\n",
    "- Enable meta-optimizer to find optimal alpha\n",
    "- Test different countries or time horizons\n",
    "- Compare MPC results with single-pass optimization\n",
    "- Analyze iteration-level performance for optimization opportunities\n",
    "\n",
    "### Configuration file reference:\n",
    "- `mpc_config.json`: MPC horizon/execution settings\n",
    "- `mpc_test_config.json`: Test scenario parameters (country, duration, alpha, visualization options)\n",
    "- `solver_config.json`: Solver timeouts and tolerances\n",
    "- `aging_config.json`: Degradation model parameters\n",
    "- `afrr_ev_weights_config.json`: aFRR activation probabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bess_ems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
